{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjrr0Pb8XLKK8l/Tr4cfdQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DevBatra05/DeepLearningLab/blob/main/Lab_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "do8zvZwJGdjg",
        "outputId": "924d6a48-4656-40f7-b163-d119f313253b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0,0 -> 0\n",
            "0,1 -> 0\n",
            "1,0 -> 0\n",
            "1,1 -> 1\n"
          ]
        }
      ],
      "source": [
        "def perceptron_and(x1, x2):\n",
        "    w1, w2, bias = 1, 1, -1\n",
        "    z = w1*x1 + w2*x2 + bias\n",
        "    return 1 if z > 0 else 0\n",
        "\n",
        "# Verify all input combinations\n",
        "for x1, x2 in [(0,0),(0,1),(1,0),(1,1)]:\n",
        "    print(f\"{x1},{x2} -> {perceptron_and(x1,x2)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# XOR dataset\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]], dtype=float)\n",
        "Y = np.array([[0],[1],[1],[0]], dtype=float)\n",
        "\n",
        "# Define a small MLP: 2 inputs -> 2 hidden -> 1 output\n",
        "model = Sequential([\n",
        "    Dense(2, activation='sigmoid', input_shape=(2,)),  # hidden layer\n",
        "    Dense(1, activation='sigmoid')                    # output layer\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X, Y, epochs=500, verbose=0)\n",
        "preds = (model.predict(X) > 0.5).astype(int)\n",
        "print(\"Predictions:\", preds.T, \"Actual:\", Y.T)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYmLnlL4SkK0",
        "outputId": "2be2e336-0158-4ae0-fe7a-76c4af414da1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "Predictions: [[0 1 1 0]] Actual: [[0. 1. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "import kagglehub\n",
        "\n",
        "# Download dataset\n",
        "data_path = kagglehub.dataset_download(\"gti-upm/leapgestrecog\")\n",
        "print(\"Dataset Path:\", data_path)\n",
        "\n",
        "# Go inside \"leapGestRecog\" folder if present\n",
        "if \"leapGestRecog\" in os.listdir(data_path):\n",
        "    data_path = os.path.join(data_path, \"leapGestRecog\")\n",
        "\n",
        "print(\"Using data folder:\", data_path)\n",
        "\n",
        "# Load dataset\n",
        "X, y = [], []\n",
        "for person in os.listdir(data_path):\n",
        "    person_path = os.path.join(data_path, person)\n",
        "    if not os.path.isdir(person_path):\n",
        "        continue\n",
        "    for gesture in os.listdir(person_path):\n",
        "        gesture_path = os.path.join(person_path, gesture)\n",
        "        if not os.path.isdir(gesture_path):\n",
        "            continue\n",
        "        for img_file in os.listdir(gesture_path):\n",
        "            img_path = os.path.join(gesture_path, img_file)\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # grayscale\n",
        "            if img is None:\n",
        "                continue\n",
        "            img = cv2.resize(img, (50, 50))                  # resize to 50x50\n",
        "            X.append(img.flatten())                          # flatten into 1D\n",
        "            y.append(gesture)                                # label = gesture name\n",
        "\n",
        "X = np.array(X, dtype=\"float32\") / 255.0  # normalize\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"Dataset loaded:\", X.shape, y.shape)\n",
        "\n",
        "# One-hot encode labels\n",
        "encoder = LabelBinarizer()\n",
        "y = encoder.fit_transform(y)\n",
        "print(\"Classes:\", encoder.classes_)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Build MLP model\n",
        "model = Sequential([\n",
        "    Dense(512, activation='relu', input_shape=(2500,)),  # 50*50=2500 features\n",
        "    Dropout(0.3),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(y.shape[1], activation='softmax')              # number of gesture classes\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "history = model.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {acc*100:.2f}%\")\n",
        "\n",
        "# Predictions\n",
        "preds = np.argmax(model.predict(X_test[:10]), axis=1)\n",
        "actual = np.argmax(y_test[:10], axis=1)\n",
        "print(\"Predictions:\", preds)\n",
        "print(\"Actual:\", actual)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi6omBD5SnrS",
        "outputId": "47bb453b-86d8-4522-ac83-63e7732a726c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'leapgestrecog' dataset.\n",
            "Dataset Path: /kaggle/input/leapgestrecog\n",
            "Using data folder: /kaggle/input/leapgestrecog/leapGestRecog\n",
            "Dataset loaded: (20000, 2500) (20000,)\n",
            "Classes: ['01_palm' '02_l' '03_fist' '04_fist_moved' '05_thumb' '06_index' '07_ok'\n",
            " '08_palm_moved' '09_c' '10_down']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.5599 - loss: 1.2956 - val_accuracy: 0.9822 - val_loss: 0.1021\n",
            "Epoch 2/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9646 - loss: 0.1379 - val_accuracy: 0.9966 - val_loss: 0.0263\n",
            "Epoch 3/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9837 - loss: 0.0602 - val_accuracy: 0.9984 - val_loss: 0.0119\n",
            "Epoch 4/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9860 - loss: 0.0434 - val_accuracy: 0.9984 - val_loss: 0.0084\n",
            "Epoch 5/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 21ms/step - accuracy: 0.9898 - loss: 0.0345 - val_accuracy: 0.9987 - val_loss: 0.0087\n",
            "Epoch 6/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9911 - loss: 0.0296 - val_accuracy: 0.9997 - val_loss: 0.0037\n",
            "Epoch 7/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9935 - loss: 0.0198 - val_accuracy: 0.9991 - val_loss: 0.0031\n",
            "Epoch 8/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9940 - loss: 0.0166 - val_accuracy: 0.9987 - val_loss: 0.0043\n",
            "Epoch 9/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9949 - loss: 0.0194 - val_accuracy: 0.9984 - val_loss: 0.0054\n",
            "Epoch 10/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9955 - loss: 0.0161 - val_accuracy: 0.9991 - val_loss: 0.0046\n",
            "Epoch 11/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9901 - loss: 0.0279 - val_accuracy: 0.9984 - val_loss: 0.0049\n",
            "Epoch 12/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9909 - loss: 0.0309 - val_accuracy: 0.9994 - val_loss: 0.0027\n",
            "Epoch 13/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9950 - loss: 0.0136 - val_accuracy: 0.9997 - val_loss: 0.0015\n",
            "Epoch 14/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.9968 - loss: 0.0127 - val_accuracy: 0.9994 - val_loss: 0.0029\n",
            "Epoch 15/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9967 - loss: 0.0118 - val_accuracy: 0.9997 - val_loss: 0.0012\n",
            "Epoch 16/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9924 - loss: 0.0232 - val_accuracy: 0.9991 - val_loss: 0.0054\n",
            "Epoch 17/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9949 - loss: 0.0194 - val_accuracy: 0.9981 - val_loss: 0.0059\n",
            "Epoch 18/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.9934 - loss: 0.0211 - val_accuracy: 0.9984 - val_loss: 0.0071\n",
            "Epoch 19/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.9940 - loss: 0.0168 - val_accuracy: 0.9931 - val_loss: 0.0148\n",
            "Epoch 20/20\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.9932 - loss: 0.0229 - val_accuracy: 0.9994 - val_loss: 0.0030\n",
            "Test Accuracy: 99.92%\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
            "Predictions: [3 7 4 9 0 2 6 8 3 0]\n",
            "Actual: [3 7 4 9 0 2 6 8 3 0]\n"
          ]
        }
      ]
    }
  ]
}